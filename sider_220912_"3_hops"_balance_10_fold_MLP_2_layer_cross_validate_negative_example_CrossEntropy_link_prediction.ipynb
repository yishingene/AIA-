{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1mMGTJVqvJTzen-oNqIpLVXMSzhuCA10N",
      "authorship_tag": "ABX9TyNuRd1vMTwOQ1kh2RsY373K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yishingene/AIA-reading/blob/master/sider_220912_%223_hops%22_balance_10_fold_MLP_2_layer_cross_validate_negative_example_CrossEntropy_link_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa9EYp_ZTFDI"
      },
      "source": [
        "# use negative example (not negative sampling!!s)\n",
        "# ref https://docs.dgl.ai/en/latest/new-tutorial/4_link_predict.html"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfXG7OSEQyBD",
        "outputId": "437cd59b-b5d5-47d4-cc3e-f5e0296fcdf0"
      },
      "source": [
        "!pip install dgl"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dgl) (4.64.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (5.9.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.7.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfJNvegcSeJm"
      },
      "source": [
        "import pandas as pd\n",
        "# import itertools\n",
        "# import scipy.sparse as sp\n",
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from dgl.data.utils import generate_mask_tensor\n",
        "from dgl.data import DGLDataset\n",
        "import torch\n",
        "import scipy.sparse as sp\n",
        "# from sklearn.metrics import roc_auc_score,precision_recall_curve, auc, ndcg_score, mean_squared_error\n",
        "from sklearn.metrics import roc_auc_score,precision_recall_curve, auc, f1_score,precision_score, recall_score,average_precision_score,label_ranking_average_precision_score\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi_363TJSxa5",
        "outputId": "213e85fb-885e-4d1b-dd34-6299e5044484"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/sideeffects/data/side-effect-and-drug_name.tsv\",sep = \"\\t\")\n",
        "drug_id = df[\"drugbank_id\"]\n",
        "drug_name = df[\"drugbank_name\"] \n",
        "side_effect =df[\"side_effect_name\"] \n",
        "edgelist1 = zip(side_effect, drug_name)\n",
        "dfs = df[['drugbank_name','side_effect_name']]\n",
        "\n",
        "col_names = [\"left_side\",\"right_side\",\"similairity\"]\n",
        "drugsim = pd.read_csv(\"/content/drive/MyDrive/sideeffects/data/semantic_similarity_side_effects_drugs.txt\",sep =\"\\t\",\n",
        "                 names =col_names, header=None)\n",
        "source =drugsim[\"left_side\"]\n",
        "destination = drugsim[\"right_side\"]\n",
        "similarity = drugsim[\"similairity\"]\n",
        "###Drugs similarity Network#####\n",
        "edge_list = zip(source,destination,similarity)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder , LabelBinarizer\n",
        "# from sklearn import preprocessing\n",
        "# lb = preprocessing.LabelBinarizer()\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "# lb = preprocessing.LabelBinarizer()\n",
        "# dfs : drug-sideeffect, drug_id: one_hot_encode\n",
        "le.fit(dfs['drugbank_name'])\n",
        "dfs['drug_id']=le.transform(dfs['drugbank_name']) \n",
        "drugsim['drug_id_left']=le.transform(drugsim['left_side'])\n",
        "drugsim['drug_id_right']=le.transform(drugsim['right_side'])\n",
        "# lb.fit(dfs['drug_id'])\n",
        "# dfs['drug_id_onehot']=pd.DataFrame([[i] for i in lb.transform(dfs['drug_id'])])\n",
        "# drugsim['drugid_left_onehot']=pd.DataFrame([[i] for i in lb.transform(drugsim['drug_id_left'])])\n",
        "# drugsim['drugid_right_onehot']=pd.DataFrame([[i] for i in lb.transform(drugsim['drug_id_right'])])\n",
        "# drugsim['left_side']\n",
        "le.fit(dfs['side_effect_name'])\n",
        "dfs['se_id']=le.transform(dfs['side_effect_name'])\n",
        "# dfs['se_id_onehot']=pd.DataFrame([[i] for i in lb.transform(dfs['se_id'])])\n",
        "# drugsim: drug-drug similarity\n",
        "\n",
        " # drug-side effect: dfs\n",
        "drug_id = torch.LongTensor(dfs['drug_id'])\n",
        "side_id = torch.LongTensor(dfs['se_id'])\n",
        "\n",
        "# drug-drug similar: drugsim\n",
        "src = torch.LongTensor(drugsim['drug_id_left']) \n",
        "dst = torch.LongTensor(drugsim['drug_id_right'])   \n",
        "\n",
        " # Build graph\n",
        "G = dgl.heterograph({\n",
        "    # Heterogeneous graphs are organized as a dictionary of edges connecting two types of nodes.\n",
        "    # We specify the edges of a type simply with a pair of user ID array and item ID array.\n",
        "    ('drug_id', 'relate', 'side_id'): (drug_id, side_id),\n",
        "    # Since DGL graphs are directional, we need an inverse relation from items to users as well.\n",
        "    ('side_id', 'relate-by', 'drug_id'): (side_id, drug_id),\n",
        "    ('drug_id','similar','drug_id'):(src,dst),\n",
        "    ('drug_id','similar-by','drug_id'):(dst,src)\n",
        "})\n",
        "\n",
        "edge_weight2 = torch.tensor(drugsim['similairity'].to_numpy()) # drug-drug similar\n",
        "G.edges['similar'].data['sim'] = edge_weight2\n",
        "G.edges['similar-by'].data['sim'] = edge_weight2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv7HiczTTIbP",
        "outputId": "85663e69-50d2-4f17-d961-246086a63d1f"
      },
      "source": [
        "G"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes={'drug_id': 1020, 'side_id': 5599},\n",
              "      num_edges={('drug_id', 'relate', 'side_id'): 133750, ('drug_id', 'similar', 'drug_id'): 519690, ('drug_id', 'similar-by', 'drug_id'): 519690, ('side_id', 'relate-by', 'drug_id'): 133750},\n",
              "      metagraph=[('drug_id', 'side_id', 'relate'), ('drug_id', 'drug_id', 'similar'), ('drug_id', 'drug_id', 'similar-by'), ('side_id', 'drug_id', 'relate-by')])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZiyJUq__sRL",
        "outputId": "0bd9e3eb-8655-418e-ddca-d500eaa8b0ab"
      },
      "source": [
        "# 從 node pair 找 edge id\n",
        "G.edge_ids(torch.tensor([0, 0]), torch.tensor([3410, 1008]),etype='relate')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([100,  30])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvIPmMmQ__sU",
        "outputId": "a0058e53-4713-44aa-c074-4b8abf4d425f"
      },
      "source": [
        "G.find_edges(torch.tensor([100, 30,8]), 'relate-by')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3410, 1008,  236]), tensor([0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQmk-9Fa_Wzs",
        "outputId": "0b2692b6-35fa-4e11-c985-0b10a6e53e53"
      },
      "source": [
        "# 從 edge ID return node pair, 找 Node Pair\n",
        "G.find_edges(torch.tensor([100, 30,8]), 'relate')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 0, 0]), tensor([3410, 1008,  236]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzK_uBOBeTOL"
      },
      "source": [
        "u,v=G.edges(etype='relate')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nupuPB4Ch2JS",
        "outputId": "b9d86fd1-dcfc-4b53-c5ca-6a4f5f12be2a"
      },
      "source": [
        "eids = np.arange(G.number_of_edges(('drug_id', 'relate', 'side_id'))) # put id on edges ('drug_id', 'relate', 'side_id')\n",
        "eids"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([     0,      1,      2, ..., 133747, 133748, 133749])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjR-x_GyiGIC"
      },
      "source": [
        "# Find all negative edges and split them for training and testing\n",
        "# 使用 u, v 當作 coordinate, 填入 '1'\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy()))) # 把 source node, dst node 放進 sparse matrix, \n",
        "# 有連接的為1, 沒有連接的為0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55J_qagCicOg"
      },
      "source": [
        "# adj.toarray()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibrkMKBIlAop",
        "outputId": "d1c1b98e-ca5f-4bb6-a243-c947a3df16ea"
      },
      "source": [
        "adj_neg = 1 - adj.todense() # 未連接為1 , 已連接為 0\n",
        "adj_neg"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [0., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EpIE9BQmAkf"
      },
      "source": [
        "neg_u, neg_v = np.where(adj_neg != 0) # 找出未連接 node"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZgV28p0NV-D",
        "outputId": "60b68ceb-28ab-4dd1-8913-58e9a777f91c"
      },
      "source": [
        "len(v)/(len(v)+len(neg_u)) # link 在 graph 中佔比"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.023419798353347412"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PabvOtDqLb4"
      },
      "source": [
        "# eids_pm = np.random.permutation(eids) # 亂數排列"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqAqLbD9Ytd0"
      },
      "source": [
        "class HeteroDotProductPredictor(nn.Module):\n",
        "    def forward(self, graph, h, etype):\n",
        "        # h contains the node representations for each node type computed from\n",
        "        # the GNN defined in the previous section (Section 5.1).\n",
        "        with graph.local_scope():\n",
        "            # print('h:',h)\n",
        "            # print('graph',graph)\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'), etype=etype)\n",
        "            return graph.edges[etype].data['score']\n",
        "\n",
        "\n",
        "class HeteroMLPPredictor(nn.Module):\n",
        "    def __init__(self, in_dims, n_classes):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(in_dims * 2, n_classes)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        x = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        y = self.W(x)\n",
        "        return {'score': y}\n",
        "\n",
        "    def forward(self, graph, h,etype):\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h   \n",
        "            graph.apply_edges(self.apply_edges, etype=etype)\n",
        "            return graph.edges[etype].data['score']\n",
        "\n",
        "\n",
        "# 2 layer\n",
        "class Hetero2MLPPredictor(nn.Module):\n",
        "    def __init__(self, in_dims, n_classes):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(in_dims * 2, in_dims)\n",
        "        self.W2 = nn.Linear(in_dims, n_classes)\n",
        "    def apply_edges(self, edges):\n",
        "        x = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        score = self.W2(F.relu(self.W1(x)))\n",
        "        return {'score': score}\n",
        "\n",
        "    def forward(self, graph, h,etype):\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h   \n",
        "            graph.apply_edges(self.apply_edges, etype=etype)\n",
        "            return graph.edges[etype].data['score']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyFPpRtpZI3-"
      },
      "source": [
        "\n",
        "import dgl.nn as dglnn\n",
        "# https://zhuanlan.zhihu.com/p/126149099\n",
        "# https://docs.dgl.ai/guide/training-node.html?highlight=rgcn\n",
        "\n",
        "class RGCN(nn.Module): \n",
        "    def __init__(self, in_feats, hid_feats, out_feats, rel_names): # in=10,hid=20,out=5,\n",
        "        super().__init__()\n",
        "        # featureless embedding\n",
        "        embed_dict = {ntype : nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), in_feats)) # in=10\n",
        "                      for ntype in G.ntypes}\n",
        "        for key, embed in embed_dict.items():\n",
        "            nn.init.xavier_uniform_(embed)\n",
        "        self.embed = nn.ParameterDict(embed_dict)\n",
        "        # create layer\n",
        "        self.conv1 = dglnn.HeteroGraphConv({\n",
        "            rel: dglnn.GraphConv(in_feats, hid_feats) # 10,20\n",
        "            for rel in rel_names}, aggregate='sum')\n",
        "        \n",
        "        self.conv2 = dglnn.HeteroGraphConv({\n",
        "          rel: dglnn.GraphConv(hid_feats, hid_feats) # 20,20\n",
        "          for rel in rel_names}, aggregate='sum')\n",
        "                \n",
        "        self.conv3 = dglnn.HeteroGraphConv({\n",
        "            rel: dglnn.GraphConv(hid_feats, out_feats) # 20,5\n",
        "            for rel in rel_names}, aggregate='sum')\n",
        "\n",
        "    def forward(self, graph):\n",
        "        # inputs are features of nodes\n",
        "        h = self.conv1(graph, self.embed)\n",
        "        h = {k: F.relu(v) for k, v in h.items()}\n",
        "        h = self.conv2(graph, h)\n",
        "        h = {k: F.relu(v) for k, v in h.items()}\n",
        "        h = self.conv3(graph, h)\n",
        "        return h"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrWeA4H8AO7Z"
      },
      "source": [
        "fprd = dict()\n",
        "tprd = dict()\n",
        "roc_aucd = dict()\n",
        "precd = dict()\n",
        "recalld = dict()\n",
        "auc_prd = dict()\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    # print('positive score:',pos_score[:5])\n",
        "    # print('negative score:',neg_score[:5])\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    # print('scores:',scores)\n",
        "    # print('labels:',labels)\n",
        "    # ndcg = ndcg_score([labels], [scores.squeeze(1)], k=5)\n",
        "    # rmse = mean_squared_error(labels,scores, squared=False)\n",
        "    prediction_int = np.zeros_like(scores)\n",
        "    prediction_int[scores > 0.5] = 1\n",
        "    f1_micro = f1_score(labels, prediction_int, average='micro',zero_division=0)\n",
        "    f1_macro = f1_score(labels, prediction_int, average='macro',zero_division=0)\n",
        "    f1_weight = f1_score(labels, prediction_int, average='weighted',zero_division=0)\n",
        "    prec_micro = precision_score(labels, prediction_int, average='micro',zero_division=0)\n",
        "    prec_macro = precision_score(labels, prediction_int, average='macro',zero_division=0)\n",
        "    prec_weight = precision_score(labels, prediction_int, average='weighted',zero_division=0)\n",
        "    recall_micro = recall_score(labels, prediction_int, average='micro',zero_division=0)\n",
        "    recall_macro = recall_score(labels, prediction_int, average='macro',zero_division=0)\n",
        "    recall_weight = recall_score(labels, prediction_int, average='weighted',zero_division=0)\n",
        "\n",
        "    prec, recall, _ = precision_recall_curve(labels,scores)\n",
        "    pr_auc_score = auc(recall, prec)\n",
        "\n",
        "    fpr, tpr, _ = metrics.roc_curve(labels,scores)\n",
        "    roc_auc_score = metrics.auc(fpr, tpr)\n",
        "\n",
        "    # fprd[f] = fpr # algorithm\n",
        "    # tprd[f] = tpr # algorithm\n",
        "    # roc_aucd[f] = roc_auc_score # algorithm\n",
        "    # precd[f] = prec # algorithm\n",
        "    # recalld[f] = recall # algorithm\n",
        "    # auc_prd[f] = pr_auc_score # algorithm\n",
        "\n",
        "    return roc_auc_score, pr_auc_score, f1_micro, f1_macro, f1_weight, prec_micro, prec_macro, prec_weight,\\\n",
        "     recall_micro,recall_macro, recall_weight,prec, recall, fpr, tpr\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJDT-8cWZJfK"
      },
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features, rel_names):\n",
        "        super().__init__()\n",
        "        self.sage = RGCN(in_features, hidden_features, out_features, rel_names)\n",
        "        # self.pred = HeteroDotProductPredictor()\n",
        "        # self.pred = MLPPredictor(hidden_features)\n",
        "        self.pred = Hetero2MLPPredictor(out_features, 1)\n",
        "    def forward(self, g, pos_g,neg_g, etype):\n",
        "        h = self.sage(g) # process incomplete G, output information\n",
        "        pred_pos_g = self.pred(pos_g, h, etype) # use information inferring pos_g graph\n",
        "        pred_neg_g = self.pred(neg_g, h, etype) # use information inferreing neg_g graph\n",
        "        # print(\"pred_pos_g\",torch.sigmoid(pred_pos_g)) # use sigmoid transform to get prediction label\n",
        "        # print(\"pred_neg_g\",torch.sigmoid(pred_neg_g))\n",
        "        # with torch.no_grad():\n",
        "        #     valid_pos_score = self.pred(valid_pos_g, h, etype) # 這裡的 h 是全局的 G 所輸出的 h\n",
        "        #     valid_neg_score = self.pred(valid_neg_g, h, etype)\n",
        "            # roc_auc_score,pr_auc_score = compute_auc(pos_score, neg_score)\n",
        "            # print('AUC-ROC:', roc_auc_score)\n",
        "            # print('AUC-PR:', pr_auc_score)\n",
        "            \n",
        "        return torch.sigmoid(pred_pos_g), torch.sigmoid(pred_neg_g)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vqOGcZGZVwX"
      },
      "source": [
        "# https://docs.dgl.ai/en/latest/new-tutorial/4_link_predict.html\n",
        "# use cross entropy\n",
        "\n",
        "# pred = HeteroDotProductPredictor()\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).squeeze(1)\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    # print('pos_score length:',pos_score.shape[0],'neg_score length:',neg_score.shape[0])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iybXIOj9F2A7"
      },
      "source": [
        "# def setdiff2d(A,B): # set difference of two 2d array\n",
        "#     return np.array(list(set(map(tuple, A.T)) - set(map(tuple, B.T)))).T"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioe4T3WyIqN5"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHn9MGubO_Sn",
        "outputId": "3a506ed3-a47e-406f-de84-3bc4d93d8627"
      },
      "source": [
        "len(neg_u)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5577230"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzCLB90sO7eD",
        "outputId": "2412e1d3-17e2-4d49-f2b1-9f6a54d92d8c"
      },
      "source": [
        "# neg_eids = np.random.choice(len(neg_u), G.number_of_edges(('drug_id', 'relate', 'side_id')) // 2)\n",
        "neg_eids = np.random.choice(len(neg_u), G.number_of_edges(('drug_id', 'relate', 'side_id'))) # 找與 positive 同樣長度的 , 這裡之後可以用 sampling, 重複測試\n",
        "# neg_eids = np.random.choice(len(neg_u), G.number_of_edges(('drug_id', 'relate', 'side_id'))*50 ) # 1:50\n",
        "neg_eids.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(133750,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhOR90kl0_Ar"
      },
      "source": [
        "FOLDS = 10\n",
        "sz = G.number_of_edges(('drug_id', 'relate', 'side_id'))\n",
        "eids = np.arange(sz) # list: all positive edges ids, 133750個\n",
        "eids_pm = eids\n",
        "test_size = fsz = int(sz /10) # 133750 => 13775 , test size, 可以從這裡開始改 train, cross validate 10 fold  , test size 10%\n",
        "np.random.shuffle(eids_pm)\n",
        "neg_eids_pm = neg_eids\n",
        "# np.random.shuffle(neg_eids_pm)\n",
        "IDX = u,v\n",
        "IDX_neg = neg_u,neg_v\n",
        "offset = 0\n",
        "AUC_roc_train = np.zeros(FOLDS)\n",
        "AUC_roc_valid = np.zeros(FOLDS)\n",
        "AUC_roc_test = np.zeros(FOLDS)\n",
        "AUC_pr_train = np.zeros(FOLDS)\n",
        "AUC_pr_valid = np.zeros(FOLDS)\n",
        "AUC_pr_test = np.zeros(FOLDS)\n",
        "F1_micro_test = np.zeros(FOLDS)\n",
        "F1_macro_test = np.zeros(FOLDS)\n",
        "F1_weight_test = np.zeros(FOLDS)\n",
        "Prec_micro_test = np.zeros(FOLDS)\n",
        "Prec_macro_test = np.zeros(FOLDS)\n",
        "Prec_weight_test  = np.zeros(FOLDS)\n",
        "Recall_micro_test = np.zeros(FOLDS)\n",
        "Recall_macro_test = np.zeros(FOLDS)\n",
        "Recall_weight_test = np.zeros(FOLDS) "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7fjPyii1CbO"
      },
      "source": [
        "algod = {}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep49fgJ-04R-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acab3158-5855-40cb-e879-efc558f59c0f"
      },
      "source": [
        "for f in range(FOLDS):\n",
        "    print(\"== Fold:\",f,\" ==\")\n",
        "    # 取 test set,佔1/5\n",
        "    test_pos_u, test_pos_v = idx_test = u[eids_pm[offset:offset+fsz]], v[eids_pm[offset:offset+fsz]]\n",
        "    # print('length of test_pos',len(test_pos_u))\n",
        "    # test_neg_u, test_neg_v = idx_test_neg = neg_u[neg_eids_pm[offset:offset+fsz*50]], neg_v[neg_eids_pm[offset:offset+fsz*50]] # 1:50\n",
        "    test_neg_u, test_neg_v = idx_test_neg = neg_u[neg_eids_pm[offset:offset+fsz]], neg_v[neg_eids_pm[offset:offset+fsz]]\n",
        "    # print('length of test_neg',len(test_neg_u))\n",
        "    # validation set\n",
        "    # validate_pos_u, validate_pos_v = u[eids_pm[offset + fsz:offset + 2*fsz]], v[eids_pm[offset + fsz:offset + 2*fsz]]\n",
        "    # print('length of validate_pos ',len(validate_pos_u))\n",
        "    # validate_neg_u, validate_neg_v = neg_u[neg_eids_pm[offset + fsz:offset + 2*fsz]], neg_v[neg_eids_pm[offset + fsz:offset + 2*fsz]]\n",
        "    # print('length of validate_neg ',len(validate_neg_u))\n",
        "\n",
        "    # training set\n",
        "    train_pos_u, train_pos_v = u[eids_pm[np.r_[:offset,offset + fsz:len(eids_pm)]]], v[eids_pm[np.r_[:offset,offset + fsz:len(eids_pm)]]]\n",
        "    # print('length of train_pos ',len(train_pos_u))\n",
        "    train_neg_u, train_neg_v = neg_u[neg_eids_pm[np.r_[:offset,offset + fsz:len(neg_eids_pm)]]], neg_v[neg_eids_pm[np.r_[:offset,offset + fsz:len(neg_eids_pm)]]]\n",
        "    # print('length of train_neg ',len(train_neg_u))\n",
        "\n",
        "    # sub Graph: train_pos_g\n",
        "    num_nodes_dict = {'drug_id': 1020, 'side_id': 5599}\n",
        "    train_pos_g = dgl.heterograph({\n",
        "        ('drug_id', 'relate', 'side_id'): (train_pos_u, train_pos_v),\n",
        "        ('side_id', 'relate-by', 'drug_id'): (train_pos_v, train_pos_u),\n",
        "        ('drug_id','similar','drug_id'):(src,dst),\n",
        "        ('drug_id','similar-by','drug_id'):(dst,src)\n",
        "        \n",
        "    },num_nodes_dict=num_nodes_dict)\n",
        "    train_pos_g.edges['similar'].data['sim'] = edge_weight2\n",
        "    train_pos_g.edges['similar-by'].data['sim'] = edge_weight2\n",
        "\n",
        "    # sub Graph: train_neg_g \n",
        "    train_neg_g = dgl.heterograph({\n",
        "    ('drug_id', 'relate', 'side_id'): (train_neg_u, train_neg_v),\n",
        "    ('side_id', 'relate-by', 'drug_id'): (train_neg_v, train_neg_u),\n",
        "    ('drug_id','similar','drug_id'):(src,dst),\n",
        "    ('drug_id','similar-by','drug_id'):(dst,src)\n",
        "\n",
        "    },num_nodes_dict=num_nodes_dict)\n",
        "    train_neg_g.edges['similar'].data['sim'] = edge_weight2\n",
        "    train_neg_g.edges['similar-by'].data['sim'] = edge_weight2\n",
        "\n",
        "    # valid_pos_g = dgl.heterograph({\n",
        "    #     ('drug_id', 'relate', 'side_id'): (validate_pos_u, validate_pos_v),\n",
        "    #     ('side_id', 'relate-by', 'drug_id'): (validate_pos_v, validate_pos_u),\n",
        "    #     ('drug_id','similar','drug_id'):(src,dst),\n",
        "    #     ('drug_id','similar-by','drug_id'):(dst,src)\n",
        "        \n",
        "    # },num_nodes_dict=num_nodes_dict)\n",
        "    # valid_pos_g.edges['similar'].data['sim'] = edge_weight2\n",
        "    # valid_pos_g.edges['similar-by'].data['sim'] = edge_weight2\n",
        "\n",
        "\n",
        "    # valid_neg_g = dgl.heterograph({\n",
        "    #     ('drug_id', 'relate', 'side_id'): (validate_neg_u, validate_neg_v),\n",
        "    #     ('side_id', 'relate-by', 'drug_id'): (validate_neg_v, validate_neg_u),\n",
        "    #     ('drug_id','similar','drug_id'):(src,dst),\n",
        "    #     ('drug_id','similar-by','drug_id'):(dst,src)\n",
        "        \n",
        "    # },num_nodes_dict=num_nodes_dict)\n",
        "    # valid_neg_g.edges['similar'].data['sim'] = edge_weight2\n",
        "    # valid_neg_g.edges['similar-by'].data['sim'] = edge_weight2\n",
        "\n",
        "    # sub Graph: test_pos_g\n",
        "    test_pos_g = dgl.heterograph({\n",
        "    ('drug_id', 'relate', 'side_id'): (test_pos_u, test_pos_v),\n",
        "    ('side_id', 'relate-by', 'drug_id'): (test_pos_v, test_pos_u),\n",
        "    ('drug_id','similar','drug_id'):(src,dst),\n",
        "    ('drug_id','similar-by','drug_id'):(dst,src)\n",
        "\n",
        "    },num_nodes_dict=num_nodes_dict)\n",
        "    test_pos_g.edges['similar'].data['sim'] = edge_weight2\n",
        "    test_pos_g.edges['similar-by'].data['sim'] = edge_weight2\n",
        "\n",
        "    # sub Graph: test_neg_g\n",
        "    test_neg_g = dgl.heterograph({\n",
        "    ('drug_id', 'relate', 'side_id'): (test_neg_u, test_neg_v),\n",
        "    ('side_id', 'relate-by', 'drug_id'): (test_neg_v, test_neg_u),\n",
        "    ('drug_id','similar','drug_id'):(src,dst),\n",
        "    ('drug_id','similar-by','drug_id'):(dst,src)\n",
        "\n",
        "    },num_nodes_dict=num_nodes_dict)\n",
        "    test_neg_g.edges['similar'].data['sim'] = edge_weight2\n",
        "    test_neg_g.edges['similar-by'].data['sim'] = edge_weight2 \n",
        "\n",
        "    # train_g: remove test set only, offset:offset+fsz\n",
        "    train_g = dgl.remove_edges(G, eids_pm[offset:offset+fsz],'relate') \n",
        "\n",
        "    train_g = dgl.remove_edges(train_g, eids_pm[offset:offset+fsz],'relate-by') #因為對稱, 所以 edge ID 一樣,'relate'移除掉的 edge ID, 不會影響到 'relate-by'的 ID\n",
        "\n",
        "    model = Model(10, 20, 5, train_g.etypes) # inputfeatures=10, hidden_features=20, output_features=1, relation_names: train_g.etypes\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    # i=0\n",
        "    for epoch in range(300):\n",
        "        pos_score, neg_score = model(train_g,train_pos_g, train_neg_g, ('drug_id', 'relate', 'side_id'))\n",
        "        loss = compute_loss(pos_score, neg_score)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        # i=i+1\n",
        "        if epoch % 20==0:\n",
        "            print('the',epoch,'loss=',loss.item())\n",
        "            with torch.no_grad(): # 這裡似乎弄錯了, 要使用 test set, 然後在 model 中使用 validation set , \n",
        "                # pos_score = self.pred(test_pos_g, h, etype) # 這裡的 h 是全局的 G 所輸出的 h\n",
        "                # neg_score = self.pred(test_neg_g, h, etype)\n",
        "                # roc_auc_score_train,pr_auc_score_train, ndcg, rmse = compute_auc(pos_score, neg_score,f)\n",
        "                # roc_auc_score_valid,pr_auc_score_valid = compute_auc(valid_pos_score, valid_neg_score)\n",
        "                # print('AUC-ROC-TRAIN:', roc_auc_score_train,'AUC-PR-TRAIN:', pr_auc_score_train,'ndcg-TRAIN:',ndcg,'rmse-TRAIN:',rmse)\n",
        "                # print('AUC-ROC-VALID:', roc_auc_score_valid,'AUC-PR-VALID:', pr_auc_score_valid)\n",
        "                roc_auc_score_train, pr_auc_score_train , f1_micro_train, _ ,  _ ,  _ ,  _ ,  _ ,  _ , _ ,  _,\\\n",
        "                prec, recall, fpr, tpr= compute_auc(pos_score, neg_score)\n",
        "                print('roc_auc:',roc_auc_score_train,'f1 micro:',f1_micro_train)\n",
        "        # print('==',i,' epoch:',loss.item())\n",
        "\n",
        "    # test set\n",
        "    with torch.no_grad():\n",
        "        print(\"Result:\")\n",
        "        print('AUC-ROC-TRAIN:', roc_auc_score_train,'AUC-PR-TRAIN:', pr_auc_score_train)\n",
        "        AUC_roc_train[f] = roc_auc_score_train\n",
        "        AUC_pr_train[f] = pr_auc_score_train\n",
        "        # print('AUC-ROC-VALID:', roc_auc_score_valid,'AUC-PR-VALID:', pr_auc_score_valid)\n",
        "        # AUC_roc_valid[f] = roc_auc_score_valid\n",
        "        # AUC_pr_valid[f] = pr_auc_score_valid\n",
        "        pos_score, neg_score = model(train_g,test_pos_g, test_neg_g, ('drug_id', 'relate', 'side_id'))\n",
        "        # roc_auc_score_test,pr_auc_score_test, ndcg_test, rmse_test = compute_auc(pos_score, neg_score,f)\n",
        "        # print('AUC-ROC-TEST:', roc_auc_score_test,'AUC-PR-TEST:', pr_auc_score_test,'ndcg TEST:',ndcg_test,'rmse TEST:',rmse_test)\n",
        "        # AUC_roc_test[f] = roc_auc_score_test\n",
        "        # AUC_pr_test[f] = pr_auc_score_test\n",
        "        roc_auc_score_test,pr_auc_score_test, f1_micro_test, f1_macro_test, f1_weight_test, prec_micro_test,\\\n",
        "        prec_macro_test, prec_weight_test, recall_micro_test,recall_macro_test, recall_weight_test\\\n",
        "        ,prec, recall, fpr, tpr = compute_auc(pos_score, neg_score)\n",
        "        print('AUC-ROC-TEST:', roc_auc_score_test,'AUC-PR-TEST:', pr_auc_score_test)\n",
        "        AUC_roc_test[f] = roc_auc_score_test\n",
        "        AUC_pr_test[f] = pr_auc_score_test\n",
        "        F1_micro_test[f] = f1_micro_test\n",
        "        F1_macro_test[f]  = f1_macro_test\n",
        "        F1_weight_test[f]  = f1_weight_test\n",
        "        Prec_micro_test[f]  = prec_micro_test\n",
        "        Prec_macro_test[f]  = prec_macro_test\n",
        "        Prec_weight_test[f]   = prec_weight_test\n",
        "        Recall_micro_test[f]  = recall_micro_test\n",
        "        Recall_macro_test[f]  = recall_macro_test\n",
        "        Recall_weight_test[f] = recall_weight_test\n",
        "\n",
        "        algod['fold'+str(f)] = {}\n",
        "        algod['fold'+str(f)]['gcnmlp'] = {}\n",
        "        algod['fold'+str(f)]['gcnmlp']['fpr'] = fpr\n",
        "        algod['fold'+str(f)]['gcnmlp']['tpr'] = tpr\n",
        "        algod['fold'+str(f)]['gcnmlp']['roc_auc'] = roc_auc_score_test\n",
        "        algod['fold'+str(f)]['gcnmlp']['prec'] = prec\n",
        "        algod['fold'+str(f)]['gcnmlp']['recall'] = recall\n",
        "        algod['fold'+str(f)]['gcnmlp']['auc_pr'] = pr_auc_score_test\n",
        "        algod['fold'+str(f)]['gcnmlp']['F1_macro'] = f1_macro_test\n",
        "        algod['fold'+str(f)]['gcnmlp']['Prec_macro'] = prec_macro_test\n",
        "        algod['fold'+str(f)]['gcnmlp']['Recall_macro'] = recall_macro_test\n",
        "    offset += fsz\n",
        "\n",
        "# print(\"Mean AUC ROC TRAIN\", AUC_roc_train.mean(),\" \", \"Standard Deviation:\", AUC_roc_train.std())\n",
        "# # print(\"Mean AUC ROC VALID\", AUC_roc_valid.mean(),\" \", \"Standard Deviation:\", AUC_roc_valid.std())\n",
        "# print(\"Mean AUC ROC TEST\", AUC_roc_test.mean(),\" \", \"Standard Deviation:\", AUC_roc_test.std())\n",
        "# print(\"Mean AUC PR TRAIN\", AUC_pr_train.mean(),\" \", \"Standard Deviation:\", AUC_pr_train.std())\n",
        "# # print(\"Mean AUC PR VALID\", AUC_pr_valid.mean(),\" \", \"Standard Deviation:\", AUC_pr_valid.std())\n",
        "# print('Mean AUC PR TEST', AUC_pr_test.mean(),\" \", \"Standard Deviation:\", AUC_pr_test.std())\n",
        "print(\"Mean AUC ROC TEST\", AUC_roc_test.mean(),\" \", \"SD:\", AUC_roc_train.std())\n",
        "print(\"Mean AUC PR TEST\", AUC_pr_test.mean(),\" \", \"SD:\", AUC_pr_train.std())\n",
        "print(\"f1 micro test\", F1_micro_test.mean(),\" \", \"SD:\", F1_micro_test.std())\n",
        "print(\"f1_macro_test\", F1_macro_test.mean(),\" \", \"SD:\", F1_macro_test.std())\n",
        "print(\"f1_weight_test\", F1_weight_test.mean(),\" \", \"SD:\", F1_weight_test.std())\n",
        "print(\"prec_micro_test\", Prec_micro_test.mean(),\" \", \"SD:\", Prec_micro_test.std())\n",
        "print(\"prec_macro_test\", Prec_macro_test.mean(),\" \", \"SD:\", Prec_macro_test.std())\n",
        "print(\"prec_weight_test\", Prec_weight_test.mean(),\" \", \"SD:\", Prec_weight_test.std())\n",
        "print(\"recall_micro_test\", Recall_micro_test.mean(),\" \", \"SD:\", Recall_micro_test.std())\n",
        "print(\"recall_macro_test\", Recall_macro_test.mean(),\" \", \"SD:\", Recall_macro_test.std())\n",
        "print(\"recall_weight_test\", Recall_weight_test.mean(),\" \", \"SD:\", Recall_weight_test.std())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Fold: 0  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.7280669212341309\n",
            "roc_auc: 0.5806965627705908 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.6108787059783936\n",
            "roc_auc: 0.9276869697736285 f1 micro: 0.8096863966770509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.5712690949440002\n",
            "roc_auc: 0.9316201841208839 f1 micro: 0.8553894080996886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.5657386779785156\n",
            "roc_auc: 0.9397785099135295 f1 micro: 0.8605690550363447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.565657377243042\n",
            "roc_auc: 0.9401319683189755 f1 micro: 0.8635264797507787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.5655244588851929\n",
            "roc_auc: 0.9409133545244666 f1 micro: 0.8635970924195223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.5651072859764099\n",
            "roc_auc: 0.9416264537115215 f1 micro: 0.8643281412253375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.5647264122962952\n",
            "roc_auc: 0.9420958518475384 f1 micro: 0.8650508826583593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.5642494559288025\n",
            "roc_auc: 0.9427583195728992 f1 micro: 0.8660809968847352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.5635486245155334\n",
            "roc_auc: 0.943912425177033 f1 micro: 0.8672980269989615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5631883144378662\n",
            "roc_auc: 0.9447772121949298 f1 micro: 0.8681079958463136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.5630688667297363\n",
            "roc_auc: 0.945280258141042 f1 micro: 0.8683572170301143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5629718899726868\n",
            "roc_auc: 0.9456104336461538 f1 micro: 0.868282450674974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.562920868396759\n",
            "roc_auc: 0.9458155309655596 f1 micro: 0.8684735202492212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.5628836154937744\n",
            "roc_auc: 0.9459614385212358 f1 micro: 0.8690301142263759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.9459614385212358 AUC-PR-TRAIN: 0.9456161684700489\n",
            "AUC-ROC-TEST: 0.9394298611232422 AUC-PR-TEST: 0.941858828547657\n",
            "== Fold: 1  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.7293436527252197\n",
            "roc_auc: 0.9089583589186182 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.5897613763809204\n",
            "roc_auc: 0.9142988988762832 f1 micro: 0.828361370716511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.5759354829788208\n",
            "roc_auc: 0.9183748223630507 f1 micro: 0.8417985462097612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.5670889616012573\n",
            "roc_auc: 0.9388171486430967 f1 micro: 0.8649968847352025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.5658929944038391\n",
            "roc_auc: 0.9385836816887345 f1 micro: 0.8643447559709242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.5656394362449646\n",
            "roc_auc: 0.9392937226584024 f1 micro: 0.8627372793354102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.5654018521308899\n",
            "roc_auc: 0.9400646717326113 f1 micro: 0.8636677050882658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.5641654133796692\n",
            "roc_auc: 0.9424413337258416 f1 micro: 0.8664506749740395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.5634117126464844\n",
            "roc_auc: 0.9446772197215996 f1 micro: 0.8678753894080997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.5631619691848755\n",
            "roc_auc: 0.9458127617032701 f1 micro: 0.8683613707165109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5630347728729248\n",
            "roc_auc: 0.9460912575166951 f1 micro: 0.8686521287642783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.5629848837852478\n",
            "roc_auc: 0.9460963057078682 f1 micro: 0.8689055036344757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5629552602767944\n",
            "roc_auc: 0.9460615616351205 f1 micro: 0.8688473520249221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.5629100203514099\n",
            "roc_auc: 0.9460881766977332 f1 micro: 0.8690342679127726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.562887966632843\n",
            "roc_auc: 0.9460572132646228 f1 micro: 0.8685109034267912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.9460572132646228 AUC-PR-TRAIN: 0.9463021476096316\n",
            "AUC-ROC-TEST: 0.9419129454100796 AUC-PR-TEST: 0.9449858086110319\n",
            "== Fold: 2  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.732769250869751\n",
            "roc_auc: 0.7637640379352771 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.6788237690925598\n",
            "roc_auc: 0.8946311690125506 f1 micro: 0.8470072689511942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.6608227491378784\n",
            "roc_auc: 0.9025030065917666 f1 micro: 0.8657196261682243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.6480786204338074\n",
            "roc_auc: 0.9082992215612126 f1 micro: 0.8679792315680166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.6371179223060608\n",
            "roc_auc: 0.9096182843636136 f1 micro: 0.8683281412253375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.627500057220459\n",
            "roc_auc: 0.9089910796155575 f1 micro: 0.867613707165109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.6193200945854187\n",
            "roc_auc: 0.90941632648924 f1 micro: 0.8673852544132918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.6123477220535278\n",
            "roc_auc: 0.916909394176428 f1 micro: 0.86797507788162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.6064757704734802\n",
            "roc_auc: 0.9134013672141295 f1 micro: 0.8667954309449636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.6015834212303162\n",
            "roc_auc: 0.9114998823898578 f1 micro: 0.8663177570093458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5974512696266174\n",
            "roc_auc: 0.9133554948159793 f1 micro: 0.8673271028037384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.5939984917640686\n",
            "roc_auc: 0.9153565629388086 f1 micro: 0.8676386292834892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5910302400588989\n",
            "roc_auc: 0.9128480570560369 f1 micro: 0.8664299065420561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.5885009169578552\n",
            "roc_auc: 0.9146565560677572 f1 micro: 0.8667580477673935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.5863276720046997\n",
            "roc_auc: 0.9149375298419509 f1 micro: 0.86667497403946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.9149375298419509 AUC-PR-TRAIN: 0.9324543217867325\n",
            "AUC-ROC-TEST: 0.9145842606341167 AUC-PR-TEST: 0.9321036931658496\n",
            "== Fold: 3  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.7195346355438232\n",
            "roc_auc: 0.639206791997576 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.5865492820739746\n",
            "roc_auc: 0.9308002297596749 f1 micro: 0.8118047767393561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.5653066635131836\n",
            "roc_auc: 0.9405193991345409 f1 micro: 0.8624382139148493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.5650579929351807\n",
            "roc_auc: 0.9409478572952082 f1 micro: 0.8645607476635514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.565418004989624\n",
            "roc_auc: 0.9412163879534468 f1 micro: 0.8630114226375909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.5656200647354126\n",
            "roc_auc: 0.9412490720392853 f1 micro: 0.8632606438213914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.5653345584869385\n",
            "roc_auc: 0.941353620921122 f1 micro: 0.8638338525441329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.5650342702865601\n",
            "roc_auc: 0.9414299601733506 f1 micro: 0.8644527518172379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.5648454427719116\n",
            "roc_auc: 0.9415590108877911 f1 micro: 0.8646978193146417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.5646639466285706\n",
            "roc_auc: 0.9416958173930765 f1 micro: 0.8649636552440291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5645634531974792\n",
            "roc_auc: 0.9416637864064896 f1 micro: 0.865595015576324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.5644952058792114\n",
            "roc_auc: 0.9416027388968146 f1 micro: 0.8660145379023884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5644285082817078\n",
            "roc_auc: 0.9415697228611264 f1 micro: 0.865748701973001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.5644422173500061\n",
            "roc_auc: 0.9415664408363875 f1 micro: 0.863717549325026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.5643435120582581\n",
            "roc_auc: 0.9414963324415633 f1 micro: 0.8660228452751817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.9414963324415633 AUC-PR-TRAIN: 0.9392078553764154\n",
            "AUC-ROC-TEST: 0.9348403193291991 AUC-PR-TEST: 0.9341980781920232\n",
            "== Fold: 4  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.7148232460021973\n",
            "roc_auc: 0.6080713859531643 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.5797811150550842\n",
            "roc_auc: 0.9286597051572782 f1 micro: 0.8273146417445483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.5654758810997009\n",
            "roc_auc: 0.9411285315252074 f1 micro: 0.8628245067497404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.5655726194381714\n",
            "roc_auc: 0.9413023944341464 f1 micro: 0.8632855659397716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.5657183527946472\n",
            "roc_auc: 0.9418622879652006 f1 micro: 0.8627414330218068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.5656862854957581\n",
            "roc_auc: 0.9420793204344764 f1 micro: 0.8627414330218068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.5650746822357178\n",
            "roc_auc: 0.9424000054864893 f1 micro: 0.8639501557632399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.564620852470398\n",
            "roc_auc: 0.943026930699646 f1 micro: 0.8646895119418483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.5642502307891846\n",
            "roc_auc: 0.9438829916462594 f1 micro: 0.8656240913811007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.563834547996521\n",
            "roc_auc: 0.9447885355494954 f1 micro: 0.8665005192107996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5633264183998108\n",
            "roc_auc: 0.9453375820843699 f1 micro: 0.8678172377985462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.5630583167076111\n",
            "roc_auc: 0.9454273462235636 f1 micro: 0.8683281412253375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5630450248718262\n",
            "roc_auc: 0.9454610485189823 f1 micro: 0.8686728971962617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.5629818439483643\n",
            "roc_auc: 0.9454467610800016 f1 micro: 0.8683322949117341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.5629805326461792\n",
            "roc_auc: 0.9454811785858703 f1 micro: 0.8689179646936657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.9454811785858703 AUC-PR-TRAIN: 0.9463524542446099\n",
            "AUC-ROC-TEST: 0.9410340815791772 AUC-PR-TEST: 0.943329483889803\n",
            "== Fold: 5  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.7158762216567993\n",
            "roc_auc: 0.38373343057186515 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.6008866429328918\n",
            "roc_auc: 0.9323672224885671 f1 micro: 0.7984215991692627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.5648962259292603\n",
            "roc_auc: 0.9399434207009292 f1 micro: 0.8647808930425753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.565098762512207\n",
            "roc_auc: 0.9396328187808737 f1 micro: 0.8646770508826583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.565311849117279\n",
            "roc_auc: 0.9406358366863674 f1 micro: 0.8634226375908619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.5655340552330017\n",
            "roc_auc: 0.9410646957403148 f1 micro: 0.8634101765316718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.5651727914810181\n",
            "roc_auc: 0.9413190255701884 f1 micro: 0.8639335410176532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.5649018287658691\n",
            "roc_auc: 0.941492974917212 f1 micro: 0.8645233644859814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.5647322535514832\n",
            "roc_auc: 0.9414571309931645 f1 micro: 0.8648016614745587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.5647327303886414\n",
            "roc_auc: 0.9413346452598694 f1 micro: 0.862404984423676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5645098090171814\n",
            "roc_auc: 0.9412761445853808 f1 micro: 0.86533748701973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.5644365549087524\n",
            "roc_auc: 0.9412305261875262 f1 micro: 0.8654994807892004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5643693804740906\n",
            "roc_auc: 0.9411909131489191 f1 micro: 0.8652128764278296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.5644164681434631\n",
            "roc_auc: 0.9411681689252067 f1 micro: 0.8673187954309449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.5643081665039062\n",
            "roc_auc: 0.9411350732491597 f1 micro: 0.8660477673935618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.9411350732491597 AUC-PR-TRAIN: 0.9396818492475136\n",
            "AUC-ROC-TEST: 0.9363798186741199 AUC-PR-TEST: 0.9364036959371842\n",
            "== Fold: 6  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.7097287774085999\n",
            "roc_auc: 0.4600863628264477 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.5780444741249084\n",
            "roc_auc: 0.9187344673199126 f1 micro: 0.8302596053997922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.5662464499473572\n",
            "roc_auc: 0.9392019253781396 f1 micro: 0.8644818276220145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.5653257966041565\n",
            "roc_auc: 0.9412394025334037 f1 micro: 0.8646479750778816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.5654751062393188\n",
            "roc_auc: 0.9418145569239429 f1 micro: 0.863381100726895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.565373957157135\n",
            "roc_auc: 0.9420570862472221 f1 micro: 0.8639003115264797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.565000593662262\n",
            "roc_auc: 0.9422795061728395 f1 micro: 0.864656282450675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.5646487474441528\n",
            "roc_auc: 0.94261253158128 f1 micro: 0.8652419522326065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.5642112493515015\n",
            "roc_auc: 0.9431477406728066 f1 micro: 0.8659023883696781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.5637625455856323\n",
            "roc_auc: 0.9439481252101376 f1 micro: 0.8666417445482866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5633001327514648\n",
            "roc_auc: 0.9449002677984707 f1 micro: 0.8676469366562825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.5628865361213684\n",
            "roc_auc: 0.9454860704293544 f1 micro: 0.8700934579439252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5628163814544678\n",
            "roc_auc: 0.9452866953456499 f1 micro: 0.8692959501557632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.5627651810646057\n",
            "roc_auc: 0.94536259150349 f1 micro: 0.8689345794392523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.5627458691596985\n",
            "roc_auc: 0.9454211857933574 f1 micro: 0.8688598130841122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.9454211857933574 AUC-PR-TRAIN: 0.9463337797328242\n",
            "AUC-ROC-TEST: 0.9399196492270068 AUC-PR-TEST: 0.943499887182933\n",
            "== Fold: 7  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.7371602654457092\n",
            "roc_auc: 0.3026828629553069 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.5857350826263428\n",
            "roc_auc: 0.9167260689714666 f1 micro: 0.8344215991692628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.5734614729881287\n",
            "roc_auc: 0.9275151556715827 f1 micro: 0.851368639667705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.565888524055481\n",
            "roc_auc: 0.9402506413563533 f1 micro: 0.8627455867082037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.565751314163208\n",
            "roc_auc: 0.9399168963551725 f1 micro: 0.8640373831775702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.56572026014328\n",
            "roc_auc: 0.9405961906253066 f1 micro: 0.8631609553478712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.5653740763664246\n",
            "roc_auc: 0.9409692798961362 f1 micro: 0.8637383177570094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.5651481747627258\n",
            "roc_auc: 0.9413057410200256 f1 micro: 0.8640623052959502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.564881443977356\n",
            "roc_auc: 0.9416336341456314 f1 micro: 0.864656282450675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.5646348595619202\n",
            "roc_auc: 0.941862878194117 f1 micro: 0.8650716510903427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5645052790641785\n",
            "roc_auc: 0.9419157018360544 f1 micro: 0.8651588785046728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.564441978931427\n",
            "roc_auc: 0.9418373249914542 f1 micro: 0.8650467289719627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5644001960754395\n",
            "roc_auc: 0.9417701393425917 f1 micro: 0.8650176531671859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.5643699765205383\n",
            "roc_auc: 0.9416960648716961 f1 micro: 0.8649844236760125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.5643577575683594\n",
            "roc_auc: 0.9416117623427136 f1 micro: 0.8647725856697819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.9416117623427136 AUC-PR-TRAIN: 0.9402322643357338\n",
            "AUC-ROC-TEST: 0.9370314263254432 AUC-PR-TEST: 0.9373841455667911\n",
            "== Fold: 8  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.713901698589325\n",
            "roc_auc: 0.8421530741355383 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.6422778367996216\n",
            "roc_auc: 0.9048413400749863 f1 micro: 0.8562159916926272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.6264923214912415\n",
            "roc_auc: 0.9021012975503816 f1 micro: 0.8644278296988578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.6173165440559387\n",
            "roc_auc: 0.9093086089701079 f1 micro: 0.8666708203530633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.6099137663841248\n",
            "roc_auc: 0.9137129989378552 f1 micro: 0.8668245067497404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.603437602519989\n",
            "roc_auc: 0.9126582021352883 f1 micro: 0.8671401869158879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.5982877612113953\n",
            "roc_auc: 0.9134951275878317 f1 micro: 0.8670944963655244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.5940477252006531\n",
            "roc_auc: 0.9111601412080843 f1 micro: 0.8650924195223261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.5904313921928406\n",
            "roc_auc: 0.9144419589095603 f1 micro: 0.8670571131879543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.5875096917152405\n",
            "roc_auc: 0.9145437450507837 f1 micro: 0.8667040498442368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5850769877433777\n",
            "roc_auc: 0.9164263997610445 f1 micro: 0.8674641744548287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.5830355286598206\n",
            "roc_auc: 0.9146421056213869 f1 micro: 0.8657570093457944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5812733769416809\n",
            "roc_auc: 0.916058004095457 f1 micro: 0.8662845275181724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.5797660946846008\n",
            "roc_auc: 0.9175679101457995 f1 micro: 0.8670238836967809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.5784784555435181\n",
            "roc_auc: 0.91867040579532 f1 micro: 0.867239875389408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.91867040579532 AUC-PR-TRAIN: 0.9339312295871844\n",
            "AUC-ROC-TEST: 0.9095556852126824 AUC-PR-TEST: 0.9282683419687219\n",
            "== Fold: 9  ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 0 loss= 0.7204999327659607\n",
            "roc_auc: 0.22064624424581802 f1 micro: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 20 loss= 0.6399680972099304\n",
            "roc_auc: 0.9167707515260917 f1 micro: 0.8455202492211839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 40 loss= 0.5708329677581787\n",
            "roc_auc: 0.9317676599843212 f1 micro: 0.8532211838006231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 60 loss= 0.5654404163360596\n",
            "roc_auc: 0.9411432196159242 f1 micro: 0.8632689511941848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 80 loss= 0.5659669041633606\n",
            "roc_auc: 0.941385255707275 f1 micro: 0.8619646936656282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 100 loss= 0.5659423470497131\n",
            "roc_auc: 0.9399327091071623 f1 micro: 0.8623966770508826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 120 loss= 0.5655902028083801\n",
            "roc_auc: 0.9390561870754792 f1 micro: 0.8631443406022845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 140 loss= 0.5650240182876587\n",
            "roc_auc: 0.9407041491013824 f1 micro: 0.8639127725856698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 160 loss= 0.5648272037506104\n",
            "roc_auc: 0.9414269263518621 f1 micro: 0.8636884735202491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 180 loss= 0.564490020275116\n",
            "roc_auc: 0.9415539633867425 f1 micro: 0.8644236760124611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 200 loss= 0.5643843412399292\n",
            "roc_auc: 0.9414486668931138 f1 micro: 0.86533748701973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 220 loss= 0.564346432685852\n",
            "roc_auc: 0.941426968276921 f1 micro: 0.864398753894081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 240 loss= 0.5642925500869751\n",
            "roc_auc: 0.9413898558696698 f1 micro: 0.8663966770508826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 260 loss= 0.5642661452293396\n",
            "roc_auc: 0.9413469578732954 f1 micro: 0.8662845275181724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the 280 loss= 0.5642525553703308\n",
            "roc_auc: 0.9413121709783269 f1 micro: 0.8652502596053998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "AUC-ROC-TRAIN: 0.9413121709783269 AUC-PR-TRAIN: 0.9395876630628878\n",
            "AUC-ROC-TEST: 0.936404786444231 AUC-PR-TEST: 0.935803410913221\n",
            "Mean AUC ROC TEST 0.9331092833959298   SD: 0.010910957172725074\n",
            "Mean AUC PR TEST 0.9377835373975216   SD: 0.004868678321714095\n",
            "f1 micro test 0.8640710280373831   SD: 0.0033307739905336195\n",
            "f1_macro_test 0.863713400109668   SD: 0.0033670080993411272\n",
            "f1_weight_test 0.863713400109668   SD: 0.003367008099341093\n",
            "prec_micro_test 0.8640710280373831   SD: 0.003330773990533644\n",
            "prec_macro_test 0.8679234050197022   SD: 0.003094816210452661\n",
            "prec_weight_test 0.8679234050197022   SD: 0.003094816210452662\n",
            "recall_micro_test 0.8640710280373831   SD: 0.003330773990533644\n",
            "recall_macro_test 0.8640710280373831   SD: 0.003330773990533644\n",
            "recall_weight_test 0.8640710280373831   SD: 0.003330773990533644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZnVxufrzHZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7cd6a4-edab-4f66-e6f4-50bbfae3bb01"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (sage): RGCN(\n",
              "    (embed): ParameterDict(\n",
              "        (drug_id): Parameter containing: [torch.FloatTensor of size 1020x10]\n",
              "        (side_id): Parameter containing: [torch.FloatTensor of size 5599x10]\n",
              "    )\n",
              "    (conv1): HeteroGraphConv(\n",
              "      (mods): ModuleDict(\n",
              "        (relate): GraphConv(in=10, out=20, normalization=both, activation=None)\n",
              "        (similar): GraphConv(in=10, out=20, normalization=both, activation=None)\n",
              "        (similar-by): GraphConv(in=10, out=20, normalization=both, activation=None)\n",
              "        (relate-by): GraphConv(in=10, out=20, normalization=both, activation=None)\n",
              "      )\n",
              "    )\n",
              "    (conv2): HeteroGraphConv(\n",
              "      (mods): ModuleDict(\n",
              "        (relate): GraphConv(in=20, out=20, normalization=both, activation=None)\n",
              "        (similar): GraphConv(in=20, out=20, normalization=both, activation=None)\n",
              "        (similar-by): GraphConv(in=20, out=20, normalization=both, activation=None)\n",
              "        (relate-by): GraphConv(in=20, out=20, normalization=both, activation=None)\n",
              "      )\n",
              "    )\n",
              "    (conv3): HeteroGraphConv(\n",
              "      (mods): ModuleDict(\n",
              "        (relate): GraphConv(in=20, out=5, normalization=both, activation=None)\n",
              "        (similar): GraphConv(in=20, out=5, normalization=both, activation=None)\n",
              "        (similar-by): GraphConv(in=20, out=5, normalization=both, activation=None)\n",
              "        (relate-by): GraphConv(in=20, out=5, normalization=both, activation=None)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pred): Hetero2MLPPredictor(\n",
              "    (W1): Linear(in_features=10, out_features=5, bias=True)\n",
              "    (W2): Linear(in_features=5, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbWdllQFzdwO"
      },
      "source": [
        "# from torchsummary import summary"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex2_aggO0mL5"
      },
      "source": [
        "# summary(model,(1,10))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqgq0Dy3fviA",
        "outputId": "ca1756db-2bb9-4c33-aa0a-0ffafed3c934"
      },
      "source": [
        "algod['fold0']"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gcnmlp': {'fpr': array([0.00000000e+00, 2.24299065e-04, 3.73831776e-04, ...,\n",
              "         9.99028037e-01, 9.99177570e-01, 1.00000000e+00]),\n",
              "  'tpr': array([0.        , 0.09517757, 0.13106542, ..., 1.        , 1.        ,\n",
              "         1.        ]),\n",
              "  'roc_auc': 0.9394298611232422,\n",
              "  'prec': array([0.50063632, 0.50061763, 0.50063637, ..., 0.99715586, 0.9976489 ,\n",
              "         1.        ]),\n",
              "  'recall': array([1.        , 0.99992523, 0.99992523, ..., 0.13106542, 0.09517757,\n",
              "         0.        ]),\n",
              "  'auc_pr': 0.941858828547657,\n",
              "  'F1_macro': 0.8643230915401123,\n",
              "  'Prec_macro': 0.8689215289391291,\n",
              "  'Recall_macro': 0.8647102803738318}}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL0s2gig1MCU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e68e237f-9730-4664-813e-8bc32c1803ba"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "# file =  \"/content/drive/MyDrive/sideeffects/data/algod_gcnmlp2layer3hop0731.pickle\"\n",
        "file =  \"/content/drive/MyDrive/sideeffects/data/algod_gcnmlp2layer3hop0731.pickle\"\n",
        "if os.path.exists(file): # check file exist\n",
        "    print('檔案已經存在')\n",
        "    print(file)\n",
        "    sys.exit()\n",
        "with open(file, 'wb') as f:\n",
        "    pickle.dump(algod, f)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "檔案已經存在\n",
            "/content/drive/MyDrive/sideeffects/data/algod_gcnmlp2layer3hop0731.pickle\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-41rYFT6P05"
      },
      "source": [
        "# Load\n",
        "with open(file, 'rb') as f:\n",
        "    new_dict = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8igZteTICiC"
      },
      "source": [
        "!pip install twitter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIO-vC_zZFuE"
      },
      "source": [
        "from twitter import *\n",
        "\n",
        "OAUTH_TOKEN = '797713376314916864-psiiaKesuk4osHa0ohx05021YUeTWgx'\n",
        "OAUTH_SECRET = 'BAHQUgsvlwHgFFmQYoSFj91mWImcnc0l7wIcODcX7IrR6'\n",
        "CONSUMER_KEY = 'UBdUJkJBvKN5SueswwgAVBa2N'\n",
        "CONSUMER_SECRET = 'zY1brqqXvhRgzPw6Gunx7lEU7AYwNECQIIf8polq2rBtGOQpbj'\n",
        "\n",
        "t = Twitter(auth=OAuth(OAUTH_TOKEN, OAUTH_SECRET, CONSUMER_KEY, CONSUMER_SECRET))\n",
        "\n",
        "# Send a direct message\n",
        "def send_twitter(msg):\n",
        "    t.direct_messages.events.new(\n",
        "        _json={\n",
        "            \"event\": {\n",
        "                \"type\": \"message_create\",\n",
        "                \"message_create\": {\n",
        "                    \"target\": {\n",
        "                        \"recipient_id\": t.users.show(screen_name=\"ystwer\")[\"id\"]},\n",
        "                    \"message_data\": {\n",
        "                        \"text\": msg}}}})\n",
        "\n",
        "send_twitter(\"程式煮好了\")\n",
        "# 送訊息到 sasmpr"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}